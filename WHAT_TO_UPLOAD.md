# What to Upload: GitHub vs Hugging Face

## Quick Summary

| Destination | What to Upload | How |
|------------|----------------|-----|
| **GitHub** | **Everything** (entire project folder) | `git push` |
| **HF Dataset** | Raw data + train/test splits | Scripts auto-upload |
| **HF Model** | Trained model file | Scripts auto-upload |
| **HF Space** | App files (code, Dockerfile, requirements) | Scripts auto-upload |

---

## ðŸ“¦ GitHub Repository

### Upload: **Everything in the `mlops/` folder**

**What to include:**
```
mlops/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ engine_data.csv          âœ… Upload
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.csv            âœ… Upload
â”‚       â””â”€â”€ test.csv             âœ… Upload
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                   âœ… Upload
â”‚   â”œâ”€â”€ config.py                âœ… Upload
â”‚   â”œâ”€â”€ data_prep.py             âœ… Upload
â”‚   â”œâ”€â”€ data_register.py         âœ… Upload
â”‚   â”œâ”€â”€ train.py                 âœ… Upload
â”‚   â”œâ”€â”€ inference.py             âœ… Upload
â”‚   â”œâ”€â”€ deploy_to_hf.py         âœ… Upload
â”‚   â”œâ”€â”€ eda.py                  âœ… Upload
â”‚   â”œâ”€â”€ hf_data_utils.py        âœ… Upload
â”‚   â””â”€â”€ hf_model_utils.py       âœ… Upload
â”œâ”€â”€ notebooks/                   âœ… Upload (if you have EDA notebooks)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.joblib        âš ï¸ Optional (large file)
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ pipeline.yml         âœ… Upload (IMPORTANT!)
â”œâ”€â”€ requirements.txt             âœ… Upload
â”œâ”€â”€ Dockerfile                   âœ… Upload
â”œâ”€â”€ README.md                    âœ… Upload
â””â”€â”€ *.md files                   âœ… Upload (documentation)

âŒ DON'T upload:
â”œâ”€â”€ .venv/                       âŒ Skip (virtual environment)
â”œâ”€â”€ __pycache__/                 âŒ Skip (Python cache)
â”œâ”€â”€ mlruns/                      âŒ Skip (MLflow tracking - can be large)
â””â”€â”€ .git/                        âŒ Skip (git metadata)
```

### How to Upload to GitHub:

```bash
cd /Users/ananttripathi/Desktop/mlops

# Initialize git (if not already done)
git init

# Create .gitignore to exclude large/unnecessary files
cat > .gitignore << EOF
.venv/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
mlruns/
*.log
.DS_Store
EOF

# Add all files
git add .

# Commit
git commit -m "Initial commit: Predictive Maintenance MLOps Pipeline"

# Add remote (replace with your repo URL)
git remote add origin https://github.com/ananttripathi/engine-predictive-maintenance.git

# Push
git push -u origin main
```

---

## ðŸ¤— Hugging Face - Dataset Repo

**Repo**: `ananttripathiak/engine-maintenance-dataset`

### Upload: **Data files only**

**Files uploaded automatically by scripts:**
- `data/engine_data.csv` â†’ Uploaded as `data/engine_data.csv`
- `data/processed/train.csv` â†’ Uploaded as `data/train.csv`
- `data/processed/test.csv` â†’ Uploaded as `data/test.csv`

### How to Upload:

**Option 1: Run the scripts (automatic)**
```bash
# Step 1: Register raw data
python src/data_register.py

# Step 2: Prepare and upload train/test
python src/data_prep.py
```

**Option 2: Manual upload via HF Hub**
- Go to https://huggingface.co/datasets/ananttripathiak/engine-maintenance-dataset
- Click "Add file" â†’ Upload `data/engine_data.csv`
- Upload `data/processed/train.csv` and `test.csv`

---

## ðŸ¤— Hugging Face - Model Repo

**Repo**: `ananttripathiak/engine-maintenance-model`

### Upload: **Trained model file only**

**File uploaded automatically:**
- `models/best_model.joblib` â†’ Uploaded as `model.joblib`

### How to Upload:

**Option 1: Run the training script (automatic)**
```bash
python src/train.py
# This will:
# 1. Train the model
# 2. Save to models/best_model.joblib
# 3. Upload to HF Model Repo automatically
```

**Option 2: Manual upload via HF Hub**
- Go to https://huggingface.co/ananttripathiak/engine-maintenance-model
- Click "Add file" â†’ Upload `models/best_model.joblib`
- Rename it to `model.joblib` in the repo

---

## ðŸ¤— Hugging Face - Space (Streamlit App)

**Repo**: `ananttripathiak/engine-maintenance-space`

### Upload: **App deployment files**

**Files uploaded automatically by script:**
```
âœ… src/app.py                    (Main Streamlit app)
âœ… src/inference.py             (Inference utilities)
âœ… src/config.py                (Configuration)
âœ… Dockerfile                   (Container definition)
âœ… requirements.txt             (Dependencies)
âœ… README.md                    (Documentation)
âœ… Other src/*.py files         (If needed by app)

âŒ NOT uploaded (ignored):
â”œâ”€â”€ data/                       âŒ Too large
â”œâ”€â”€ mlruns/                     âŒ MLflow tracking
â”œâ”€â”€ models/                     âŒ Model is in Model Repo
â”œâ”€â”€ .github/                    âŒ GitHub-specific
â””â”€â”€ .venv/                      âŒ Virtual environment
```

### How to Upload:

**Option 1: Run the deployment script (automatic)**
```bash
python src/deploy_to_hf.py
# This will:
# 1. Create/update the HF Space
# 2. Upload all deployment files
# 3. Configure it as a Streamlit app
```

**Option 2: Manual upload via HF Hub**
- Go to https://huggingface.co/spaces/ananttripathiak/engine-maintenance-space
- Upload files one by one or use HF CLI

---

## ðŸ“‹ Complete Upload Checklist

### âœ… Step 1: GitHub (Manual - Do First)
- [ ] Create GitHub repository
- [ ] Add `.gitignore` file
- [ ] Push entire `mlops/` folder to GitHub
- [ ] Add GitHub Secrets (HF_TOKEN, HF_DATASET_REPO, HF_MODEL_REPO, HF_SPACE_REPO)

### âœ… Step 2: Hugging Face Dataset (Automatic)
- [ ] Set `HF_TOKEN` environment variable
- [ ] Run `python src/data_register.py` (uploads raw data)
- [ ] Run `python src/data_prep.py` (uploads train/test)

### âœ… Step 3: Hugging Face Model (Automatic)
- [ ] Run `python src/train.py` (trains model and uploads to HF)

### âœ… Step 4: Hugging Face Space (Automatic)
- [ ] Run `python src/deploy_to_hf.py` (deploys app to HF Space)

### âœ… Step 5: Verify
- [ ] Check GitHub repo: https://github.com/ananttripathi/engine-predictive-maintenance
- [ ] Check HF Dataset: https://huggingface.co/datasets/ananttripathiak/engine-maintenance-dataset
- [ ] Check HF Model: https://huggingface.co/ananttripathiak/engine-maintenance-model
- [ ] Check HF Space: https://huggingface.co/spaces/ananttripathiak/engine-maintenance-space

---

## ðŸŽ¯ Key Differences

| Aspect | GitHub | Hugging Face |
|--------|--------|--------------|
| **Purpose** | Code repository & version control | Data/Model/App hosting |
| **What** | Entire project (code, data, docs) | Specific artifacts (data/model/app) |
| **How** | Manual `git push` | Automatic via scripts |
| **Size** | Can be large (includes everything) | Optimized (only what's needed) |
| **Access** | Public/Private repo | Public datasets/models/spaces |
| **CI/CD** | GitHub Actions workflow | HF Spaces auto-deploy |

---

## ðŸ’¡ Pro Tips

1. **GitHub First**: Always push to GitHub first, then run HF scripts
2. **Use .gitignore**: Exclude large files like `mlruns/` and `.venv/` from GitHub
3. **HF Scripts are Smart**: They automatically create repos if they don't exist
4. **Check File Sizes**: HF has file size limits, so scripts exclude large files
5. **GitHub Secrets**: Store HF credentials in GitHub Secrets for CI/CD

---

## ðŸš¨ Common Mistakes to Avoid

âŒ **Don't upload to GitHub:**
- Virtual environment (`.venv/`)
- Large MLflow runs (`mlruns/`)
- Python cache files (`__pycache__/`)

âŒ **Don't upload to HF Space:**
- Raw data files (too large)
- Model files (use Model Repo instead)
- MLflow tracking data

âœ… **Do upload to GitHub:**
- All source code
- Configuration files
- Documentation
- GitHub Actions workflow

âœ… **Do upload to HF:**
- Only what each repo type needs (data â†’ Dataset, model â†’ Model, app â†’ Space)

---

## ðŸ“ž Need Help?

- **GitHub Issues**: Check your repo settings and secrets
- **HF Upload Errors**: Verify `HF_TOKEN` is set correctly
- **File Size Issues**: Check HF file size limits (usually 10GB for datasets)
