## Predictive Maintenance â€“ Engine Failure Classification (MLOps Project)

> ğŸ‰ **Status: Complete** - All pipeline steps successfully deployed!

This project builds an endâ€‘toâ€‘end **predictive maintenance system** for small and large engines using sensor data (RPM, pressures, temperatures) to classify whether an engine is **healthy** or **requires maintenance**.

The work is organized to satisfy the provided **interim and final report rubrics**, including:

- âœ… **Data registration on Hugging Face**
- âœ… **Exploratory Data Analysis (EDA)**
- âœ… **Data preparation and dataset versioning**
- âœ… **Model building with experimentation tracking**
- âœ… **Model deployment with Docker + Streamlit on Hugging Face Spaces**
- âœ… **Automated GitHub Actions workflow**

---

## ğŸ”— Live Resources

### ğŸŒ Live Application
**[ğŸš€ Try the Live App](https://huggingface.co/spaces/ananttripathiak/engine-maintenance-space)**

Interactive Streamlit application for real-time engine condition predictions with sensor visualizations.

### ğŸ¤– Trained Model
**[ğŸ“¦ View Model on Hugging Face](https://huggingface.co/ananttripathiak/engine-maintenance-model)**

Trained Random Forest model with hyperparameter tuning, versioned on Hugging Face Model Hub.

### ğŸ“Š Dataset Repository
**[ğŸ“ Access Dataset Repository](https://huggingface.co/datasets/ananttripathiak/engine-maintenance-dataset)**

Version-controlled datasets including raw data and train/test splits.

### ğŸ’» GitHub Repository
**[ğŸ”§ View Source Code](https://github.com/ananttripathi/engine-predictive-maintenance)**

Complete source code, documentation, and CI/CD pipeline.

### âš™ï¸ GitHub Actions
**[ğŸ”„ View Workflow Runs](https://github.com/ananttripathi/engine-predictive-maintenance/actions)**

Automated CI/CD pipeline with 4 sequential jobs for data registration, preparation, training, and deployment.

---

## ğŸ“ Repository Structure

```
mlops/
â”œâ”€â”€ data/                          # Raw and processed data
â”‚   â”œâ”€â”€ engine_data.csv           # Original engine sensor dataset
â”‚   â””â”€â”€ processed/                # Train/test splits
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
â”œâ”€â”€ notebooks/                     # EDA and experimentation notebooks
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ config.py                 # Central configuration
â”‚   â”œâ”€â”€ data_register.py          # Register raw data to HF Dataset
â”‚   â”œâ”€â”€ data_prep.py              # Data cleaning and splitting
â”‚   â”œâ”€â”€ hf_data_utils.py          # HF Dataset Hub utilities
â”‚   â”œâ”€â”€ train.py                  # Model training with MLflow
â”‚   â”œâ”€â”€ hf_model_utils.py         # HF Model Hub utilities
â”‚   â”œâ”€â”€ inference.py              # Prediction utilities
â”‚   â”œâ”€â”€ app.py                    # Streamlit web application
â”‚   â””â”€â”€ deploy_to_hf.py          # Deploy to HF Space
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ pipeline.yml           # CI/CD pipeline
â”œâ”€â”€ Dockerfile                    # Container definition for deployment
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

### Key Files

- **`src/config.py`** â€“ Central configuration (paths, Hugging Face repo names, MLflow config)
- **`src/data_register.py`** â€“ Registers raw dataset to Hugging Face Dataset Hub
- **`src/data_prep.py`** â€“ Loads data, cleans it, and creates train/test splits
- **`src/train.py`** â€“ Model training, hyperparameter tuning, MLflow logging
- **`src/app.py`** â€“ Streamlit web application for interactive predictions
- **`src/deploy_to_hf.py`** â€“ Deploys app to Hugging Face Space
- **`.github/workflows/pipeline.yml`** â€“ Automated CI/CD pipeline

## ğŸ”„ Pipeline Overview

The MLOps pipeline consists of 6 stages, automated via GitHub Actions:

### 1. **Data Registration** âœ…
- **Script:** `src/data_register.py`
- **Action:** Creates/uses Hugging Face dataset repo and uploads raw data
- **Output:** [`ananttripathiak/engine-maintenance-dataset`](https://huggingface.co/datasets/ananttripathiak/engine-maintenance-dataset) with `data/engine_data.csv`

### 2. **Exploratory Data Analysis (EDA)**
- **Script:** `src/eda.py` (or use notebooks)
- **Action:** Performs data overview, univariate/bivariate/multivariate analysis
- **Output:** Visualizations and insights about engine health patterns

### 3. **Data Preparation** âœ…
- **Script:** `src/data_prep.py`
- **Action:** Cleans data, creates train/test splits, uploads to dataset repo
- **Output:** `data/train.csv` and `data/test.csv` in dataset repo

### 4. **Model Building + Experiment Tracking** âœ…
- **Script:** `src/train.py`
- **Action:** Trains Random Forest with hyperparameter tuning, logs to MLflow, uploads best model
- **Output:** [`ananttripathiak/engine-maintenance-model`](https://huggingface.co/ananttripathiak/engine-maintenance-model) with trained model

### 5. **Deployment & Hosting** âœ…
- **App:** `src/app.py` - Streamlit web application
- **Container:** `Dockerfile` - Container definition
- **Script:** `src/deploy_to_hf.py` - Deploys to Hugging Face Space
- **Output:** Live app at [`ananttripathiak/engine-maintenance-space`](https://huggingface.co/spaces/ananttripathiak/engine-maintenance-space)

### 6. **GitHub Actions Workflow** âœ…
- **File:** `.github/workflows/pipeline.yml`
- **Jobs:**
  1. `register-dataset` â†’ runs `src/data_register.py`
  2. `data-prep` â†’ runs `src/data_prep.py`
  3. `model-training` â†’ runs `src/train.py`
  4. `deploy-hosting` â†’ runs `src/deploy_to_hf.py`
- **View Runs:** [GitHub Actions](https://github.com/ananttripathi/engine-predictive-maintenance/actions)

---

## ğŸš€ Quick Start

### Local Development

1. **Clone the repository:**
   ```bash
   git clone https://github.com/ananttripathi/engine-predictive-maintenance.git
   cd engine-predictive-maintenance
   ```

2. **Set up virtual environment:**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Run pipeline steps:**
   ```bash
   # Register data
   python src/data_register.py
   
   # Prepare data
   python src/data_prep.py
   
   # Train model
   python src/train.py
   
   # Run app locally
   streamlit run src/app.py
   ```

### Automated Pipeline

The pipeline runs automatically on every push to `main` branch via GitHub Actions. View workflow runs at:
**[ğŸ”„ GitHub Actions](https://github.com/ananttripathi/engine-predictive-maintenance/actions)**

---

## ğŸ“Š Technologies Used

- **Python 3.10** - Programming language
- **scikit-learn** - Machine learning (Random Forest)
- **MLflow** - Experiment tracking and model registry
- **Hugging Face Hub** - Dataset, model, and space hosting
- **Streamlit** - Web application framework
- **Docker** - Containerization
- **GitHub Actions** - CI/CD automation
- **Plotly** - Interactive visualizations

## âš™ï¸ Configuration

### Current Configuration

This project is configured with:

- **Hugging Face Username:** `ananttripathiak`
- **GitHub Username:** `ananttripathi`
- **Dataset Repo:** [`ananttripathiak/engine-maintenance-dataset`](https://huggingface.co/datasets/ananttripathiak/engine-maintenance-dataset)
- **Model Repo:** [`ananttripathiak/engine-maintenance-model`](https://huggingface.co/ananttripathiak/engine-maintenance-model)
- **Space Repo:** [`ananttripathiak/engine-maintenance-space`](https://huggingface.co/spaces/ananttripathiak/engine-maintenance-space)
- **GitHub Repo:** [`ananttripathi/engine-predictive-maintenance`](https://github.com/ananttripathi/engine-predictive-maintenance)

### For New Users: Setup Instructions

#### 1. Hugging Face Configuration

**Update `src/config.py`** with your Hugging Face username:

```python
HF_DATASET_REPO = os.getenv("HF_DATASET_REPO", "ananttripathiak/engine-maintenance-dataset")
HF_MODEL_REPO = os.getenv("HF_MODEL_REPO", "ananttripathiak/engine-maintenance-model")
HF_SPACE_REPO = os.getenv("HF_SPACE_REPO", "ananttripathiak/engine-maintenance-space")
```

**Or set environment variables:**
```bash
export HF_TOKEN="hf_your_token_here"
export HF_DATASET_REPO="ananttripathiak/engine-maintenance-dataset"
export HF_MODEL_REPO="ananttripathiak/engine-maintenance-model"
export HF_SPACE_REPO="ananttripathiak/engine-maintenance-space"
```

#### 2. GitHub Repository Configuration

**A. Create GitHub Repository:**
1. Create a new repository on GitHub (e.g., `engine-predictive-maintenance`)
2. Push this `mlops` folder to it:
   ```bash
   git init
   git add .
   git commit -m "Initial commit: Predictive maintenance MLOps pipeline"
   git remote add origin https://github.com/your-username/engine-predictive-maintenance.git
   git push -u origin main
   ```

**B. Add GitHub Secrets:**
Go to your GitHub repo â†’ **Settings** â†’ **Secrets and variables** â†’ **Actions** â†’ **New repository secret**

Add these 4 secrets:
- `HF_TOKEN` â€“ Your Hugging Face access token (from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens))
- `HF_DATASET_REPO` â€“ e.g., `ananttripathiak/engine-maintenance-dataset`
- `HF_MODEL_REPO` â€“ e.g., `ananttripathiak/engine-maintenance-model`
- `HF_SPACE_REPO` â€“ e.g., `ananttripathiak/engine-maintenance-space`

**ğŸ“– For detailed setup instructions, see [`CONFIGURATION_GUIDE.md`](CONFIGURATION_GUIDE.md)**
